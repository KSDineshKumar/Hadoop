Batch Configuration
      spark.shuffle.service.enabled=true
      spark.dynamicAllocation.schedulerBacklogTimeout=1s
      spark.dynamicAllocation.executorIdleTimeout=30s
      spark.sql.hive.convertMetastoreOrc=true
      spark.sql.crossJoin.enabled=true
      spark.eventLog.enabled=false
      spark.eventLog.dir=/tmp
      spark.scheduler.mode=FAIR
      spark.memory.useLegacyMode=false
      spark.yarn.executor.memoryOverhead=4096
      spark.network.timeout=3600s
      spark.akka.timeout=1200s
      spark.rpc.askTimeout=1200s
      spark.rpc.lookupTimeout=1200s
      spark.executor.heartbeatInterval=120s
      spark.rpc.numRetries=6
      spark.task.maxFailures=8
      spark.sql.hive.caseSensitiveInferenceMode=INFER_ONLY
      spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2
      spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs=false
      spark.hadoop.fs.s3a.path.style.access=True
      spark.sql.legacy.parquet.datetimeRebaseModeInRead=LEGACY
      spark.sql.legacy.parquet.datetimeRebaseModeInWrite=CORRECTED
      spark.sql.storeAssignmentPolicy=LEGACY
      spark.sql.parquet.writeLegacyFormat=true
      spark.io.compression.codec=snappy
      spark.sql.adaptive.enabled=true
      spark.sql.adaptive.coalescePartitions.enabled=true
      spark.dynamicAllocation.shuffleTracking.enabled=true
      spark.sql.adaptive.skewJoin.enabled=true

Streaming Configuration
      spark.streaming.kafka.maxRatePerPartition = 500
      spark.broadcast.factor = org.apache.spark.broadcast.HttpBroadcastFactory
      spark.streaming.backpressure.enabled = true
      spark.streaming.receiver.maxRate=1800
      spark.streaming.backpressure.enabled=true
      spark.shuffle.manager = SORT
      spark.hadoop.mapred.output.compress = false
